\chapter{Introduction}
\section{Notes from "Basic Space Plasma Physics"}

Here we use \cite{baumjohann2012basic}. \leftsidenote{Very nice book} This book is ideal for basic space physics.
 \begin{note}
Check \href{https://www.ctan.org/pkg/tcolorbox}{tcolorbox} package for more info on these fancy boxes
 \end{note}

  
\begin{definition}{Reconnection}{theoexample}
\end{definition}

\begin{exercise}{Fancy boxes}{labbel2}
Check \href{https://www.ctan.org/pkg/tcolorbox}{tcolorbox} package for more info on these fancy boxes
\end{exercise}

\begin{exercise}{Magnetic Holes}
Solve $\frac{x}{2}=10$
\end{exercise}

\begin{question}{How is the conductivity in the diffusion region generated ? }
Good question
\end{question}

\begin{sources}{Video links}
asdasdasdasd
\end{sources}

\section{You can also add code with minted}
\subsection*{Code Example}
An example of a code can be found below. On this example, the MNIST database is used and a Neural Network is implemented for its classification.


%% The example below is trying to immitate how python looks like in highlted text
\newpage
CODE:

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=lightergray,
fontsize=\footnotesize,
linenos
]
{python}

"""
@author: Savvas Raptis, SavvasRaptis@gmail.com 
Original idea modified from  Andy Thomas (http://adventuresinmachinelearning.com)
Machine Learning Project, KU Leuven, Centre of Plasma-Astrophysics
"""

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

# Downloading and inputing MNIST database
#one_hot= True makes the input binary. Eg 5 = 0000010000
mnist = input_data.read_data_sets("data/", one_hot=True) 

# # Determine basic parameters of the dataset/model
learning_rate = 0.25 # a learning parameter
batch_size = 128 # samples that going to be propagated through the network.
epochs = 5 #How many times we read through the data

#Creating input and output placeholders for tensorflow

# input = 28 x 28 pixels = 784
x = tf.placeholder(tf.float32, [None, 784])
# output = 10 digits = 10
y = tf.placeholder(tf.float32, [None, 10])

# our model will be a simple 3 hiddel layer deep neural network
L= 400 # Our hidden layer in that case has 400 neurons
M= 200 # Our hidden layer in that case has 200 neurons
N = 150# Our hidden layer in that case has 150 neurons

# Decalting weight and biases from the input to the 1st  hiddel layer
#When using reou,  biases should have small *positive* values for example 0.01
w1 = tf.Variable(tf.random_normal([784, L], stddev=0.01), name='w1')
b1 = tf.Variable(tf.random_normal([L]), name='b1')
# Decalting weight and biases from the 1st hidden to the 2nd layer
w2 = tf.Variable(tf.random_normal([L, M], stddev=0.01), name='w2')
b2 = tf.Variable(tf.random_normal([M]), name='b2') 
# Decalting weight and biases from the 2nd hidden to the 3rd layer
w3 = tf.Variable(tf.random_normal([M, N], stddev=0.01), name='w3')
b3 = tf.Variable(tf.random_normal([N]), name='b3') 
# Decalting weight and biases from the 2nd hidden to the output layer
w4 = tf.Variable(tf.random_normal([N, 10], stddev=0.01), name='w3')
b4 = tf.Variable(tf.random_normal([10]), name='b3') 

# calculate the output of the 1st hidden layer
hidden_out = tf.add(tf.matmul(x, w1), b1)
hidden_out = tf.nn.relu(hidden_out)  #Using a Relu activation function
# calculate the output of the 2nd hidden layer
hidden_out2 = tf.add(tf.matmul(hidden_out, w2), b2)
hidden_out2 = tf.nn.relu(hidden_out2)  #Using a Relu activation function

# calculate the output of the 2nd hidden layer
hidden_out3 = tf.add(tf.matmul(hidden_out2, w3), b3)
hidden_out3 = tf.nn.relu(hidden_out3)  #Using a Relu activation function


#since we have a classification problem we use as the last activation function
#a softmax to classify between the last 10 neurons/classes
y_result = tf.nn.softmax(tf.add(tf.matmul(hidden_out3, w4), b4))

yresult_clipped = tf.clip_by_value(y_result, 1e-10, 0.9999999) 
#ensuring that we dont' get nan values

#Cross Entrpy calculation
cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(yresult_clipped)
                         + (1 - y) * tf.log(1 - yresult_clipped), axis=1))

# including an optimizer for the training process
optimiser = tf.train.GradientDescentOptimizer(
learning_rate=learning_rate).minimize(cross_entropy)

# using an initializer
initializer = tf.global_variables_initializer()

# deifning how the accuracy is calculated
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(yresult_clipped, 1))
Total_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

'''
TRAINING PROCESS
'''

# starting the training session
with tf.Session() as sess:
   # initialise the variables
   sess.run(initializer)
   total_batch = int(len(mnist.train.labels) / batch_size)
   for epoch in range(0,epochs):
        average = 0
        for i in range(total_batch):
            #using batches for x and y
            bx, by = mnist.train.next_batch(batch_size=batch_size)
            #Running the session with optimizer/cross_entropy/data parameters set
            g, c = sess.run([optimiser, cross_entropy], 
                         feed_dict={x: bx, y: by})
            #Calculating the average result on each epoch
            average += c / total_batch
        print("Epoch, Number", (epoch + 1), ":average cost =", "{:.4f}".format(average))
   print(sess.run(Total_accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))

\end{minted}
OUTPUT:
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=lightergray,
fontsize=\footnotesize,
]
{python}
Epoch, Number 1 :average cost = 2.8782
Epoch, Number 2 :average cost = 0.8372
Epoch, Number 3 :average cost = 0.3230
Epoch, Number 4 :average cost = 0.2121
Epoch, Number 5 :average cost = 0.1680
0.9703
\end{minted}
